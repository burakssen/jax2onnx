# Using `jax.eval_shape` with Shape Polymorphism in JAX 0.6.0

## Shape Polymorphism in JAX 0.6.0  
JAX 0.6.0 introduced **shape polymorphism** – the ability to treat certain dimensions as symbolic (unknown) at tracing/compile time. This is useful for handling dynamic batch sizes or other flexible dimensions in a single compiled function. In practice, JAX lets you specify **dimension variables** (like `"B"`, `"batch"`, etc.) in place of concrete sizes. These dimension variables act as placeholders for any positive integer. For example, specifying a shape as `("B", 128)` means the first dimension is a symbolic variable **B** (e.g. a dynamic batch size), while the second dimension is fixed at 128. JAX will propagate such symbols through shape inference instead of requiring a concrete value. As the JAX docs explain, you provide a **polymorphic shape** specification (as a string) to introduce one or more dimension variables (e.g. `b`) that stand for unknown dimensions ([jax/jax/experimental/jax2tf/README.md at main · jax-ml/jax · GitHub](https://github.com/google/jax/blob/main/jax/experimental/jax2tf/README.md#:~:text=The%20,are%20assumed%20to%20range%20over)). These dimension variables can be used across inputs to enforce relationships (e.g. two inputs sharing the same `'batch'` dimension), and arithmetic operations on them will produce symbolic expressions for output shapes (for instance, reshaping a `(b,4)` array into a flat vector yields an output shape `4*b` symbolically ([Shape polymorphism — JAX  documentation](https://docs.jax.dev/en/latest/export/shape_poly.html#:~:text=For%20example%2C%20in%20the%20following,as%20the%20new%20shape))).

**Key idea:** By naming a dimension (like `B` or `batch`) in the shape spec, that dimension is treated as dynamic. Any occurrence of the same name in another argument’s spec refers to the **same runtime size**, allowing you to tie shapes together. For example, `polymorphic_shapes=["(batch, _)", "(batch,)"]` for two inputs means *both* inputs share a leading dimension named `batch` (unknown at compile time) ([jax/jax/experimental/jax2tf/README.md at main · jax-ml/jax · GitHub](https://github.com/google/jax/blob/main/jax/experimental/jax2tf/README.md#:~:text=%60polymorphic_shapes%3D%5B)). An underscore (`_`) or ellipsis (`...`) can be used as wildcards for dimensions you want to fill in from actual inputs or treat as static defaults ([jax/jax/experimental/jax2tf/README.md at main · jax-ml/jax · GitHub](https://github.com/google/jax/blob/main/jax/experimental/jax2tf/README.md#:~:text=dimension%20variables%2C%20e.g.%2C%20,are%20assumed%20to%20range%20over)). In short, JAX’s shape polymorphism syntax gives you a way to declare which dimensions are flexible.

## Using `jax.eval_shape` for Symbolic Shape Inference  
**`jax.eval_shape`** is a utility that performs abstract shape inference on a function *without executing it*. It returns a placeholder object (`jax.ShapeDtypeStruct`) capturing the shape and dtype of the function’s output. Crucially, `jax.eval_shape` can operate on inputs with symbolic dimensions – treating those dimensions as dynamic and propagating them through the computation. According to the JAX docs, `jax.eval_shape` uses JAX’s abstract interpretation under the hood to compute output shapes/dtypes, as if running the function, but “without any FLOPs” (no actual data computation) ([jax.eval_shape — JAX  documentation](https://docs.jax.dev/en/latest/_autosummary/jax.eval_shape.html#:~:text=Compute%20the%20shape%2Fdtype%20of%20,without%20any%20FLOPs)). All it needs is the shape and dtype of each input. 

To use `jax.eval_shape` with shape polymorphism, you must provide **spec objects** for the inputs instead of real arrays. Typically you create these using `jax.ShapeDtypeStruct`, which takes a shape tuple and a dtype. When a dimension is symbolic, the shape tuple should contain a special symbolic dimension object. The recommended way to get that is via `jax.export.symbolic_shape("<spec>")` – this parses a shape string (like `"B, 128"`) into the internal symbolic dimension objects. In practice, you can do something like: 

```python
from jax import ShapeDtypeStruct
from jax.export import symbolic_shape

# Define a symbolic shape for an input: first dim = B (symbolic), second dim = 128 (concrete)
input_spec = ShapeDtypeStruct(symbolic_shape("B, 128"), jnp.float32)
```

Here `input_spec` represents a float32 array of shape `(B, 128)` where **B is a symbolic dimension**. You can create specs for each input of your function this way (including using the same symbol name across specs if needed). Then call `jax.eval_shape(fun, *input_specs)`. JAX will trace `fun` abstractly, carrying along the symbols through every operation. Any shape computations inside `fun` (like `x.shape[0]` or reshapes, concatenations, etc.) will produce symbolic results. If the function attempts an operation that *requires* a concrete value (e.g. indexing that depends on data values, not just shapes), JAX would error out – but pure shape computations and transformations are fine. 

**What you get back:** The result of `jax.eval_shape` is a PyTree of `ShapeDtypeStruct` objects mirroring the structure of `fun`’s output. Each such object has a `.shape` attribute, which may now contain symbols or symbolic expressions instead of concrete ints. For instance, if `fun` returns an array with the same batch dimension as the input and, say, 64 features, the output spec’s shape might be `('B', 64)`. If `fun` does something like transposing or reshaping, you might see expressions – e.g. flattening a `(B, 4)` input to 1D would yield an output shape `(4*B,)` as a symbolic expression ([Shape polymorphism — JAX  documentation](https://docs.jax.dev/en/latest/export/shape_poly.html#:~:text=For%20example%2C%20in%20the%20following,as%20the%20new%20shape)).

## Examples of `jax.eval_shape` with Symbolic Dimensions  
**1. Inferring output of a matrix multiplication with symbolic batch** – Consider a simple function `f(A, x) = A @ x` (matrix multiply) and suppose we want to allow `A`’s first dimension (and correspondingly the output’s first dimension) to be dynamic. We can denote that with a symbol (say `'a'`) in the shape. In the JAX repository’s `jax2tf` module, there’s a demonstration of exactly this. They set up: 

```python
import jax, jax.numpy as jnp
from jax.experimental import jax2tf

f = lambda A, x: jnp.sin(jnp.dot(A, x))  # example function (sin of matrix product)
# Define input shape specs: A is shape (a, b), x is shape (b, c), with a, b, c symbolic
A_spec = jax.ShapeDtypeStruct(jax.export.symbolic_shape("a, b"), jnp.float32)
x_spec = jax.ShapeDtypeStruct(jax.export.symbolic_shape("b, c"), jnp.float32)
out_spec = jax.eval_shape(f, A_spec, x_spec)
print(out_spec.shape)  # what is the abstract shape?
```

Internally, JAX will treat `a`, `b`, and `c` as unknown dimensions. The matrix multiplication requires that the inner dimensions match (A’s second dim = x’s first dim = `b`), which is satisfied symbolically. The result of `f` has shape `(a, c)` – we expect the output’s first dim to be the same `a` as A’s, and second dim the same `c` as x’s. Indeed, if you inspect the resulting shape object, it contains `("a", "c")` for the shape ([jax/jax/experimental/jax2tf/jax2tf.py at main · jax-ml/jax · GitHub](https://github.com/google/jax/blob/main/jax/experimental/jax2tf/jax2tf.py#:~:text=,A%2C%20x)). In the actual code snippet from JAX’s `jax2tf.eval_polymorphic_shape`, they got:

> **Output:** `out_spec.shape == ("a", "c")` ([jax/jax/experimental/jax2tf/jax2tf.py at main · jax-ml/jax · GitHub](https://github.com/google/jax/blob/main/jax/experimental/jax2tf/jax2tf.py#:~:text=))

This means the output is an array of shape `(a, c)` symbolically. No concrete numbers appear in that shape – just the dimension variables, indicating that the output’s size will depend on whatever `a` and `c` turn out to be at runtime. This confirms that `jax.eval_shape` correctly inferred the relationship: if `A` is `[a × b]` and `x` is `[b × c]`, then `f(A,x)` is `[a × c]` ([jax/jax/experimental/jax2tf/jax2tf.py at main · jax-ml/jax · GitHub](https://github.com/google/jax/blob/main/jax/experimental/jax2tf/jax2tf.py#:~:text=,A%2C%20x)). We did all this without any actual matrix operations on real data – JAX’s abstract interpreter handled it.

Notably, the same example also demonstrates reusing the symbolic shape info. After obtaining `out_spec`, they call another shape-inference on a function `g(y) = y.T` using the *polymorphic shape from the previous result*. The second call, with input spec corresponding to shape `(a,c)`, produces an output shape `(c, a)` (transpose swaps the symbolic dims) ([jax/jax/experimental/jax2tf/jax2tf.py at main · jax-ml/jax · GitHub](https://github.com/google/jax/blob/main/jax/experimental/jax2tf/jax2tf.py#:~:text=,out_poly_shape%5D%29%28out_spec)). This shows that these symbolic shapes can be threaded through multiple operations: e.g., `'a'` and `'c'` remain as symbols and can move around or combine (here they just swapped positions). 

**2. Dynamic batch with fixed feature dimension** – A common use-case is leaving the batch size flexible. For example, say you have `f(x) = DenseLayer(x)` where `x` is of shape `(B, 128)` (unknown batch `B`, 128 features). If `DenseLayer` produces, say, 64 outputs per feature, then `f(x)` will have shape `(B, 64)`. Using `jax.eval_shape`, you can confirm this shape polymorphically. We specify the input with shape `(B, 128)` symbolically and run `eval_shape`:

```python
x_spec = jax.ShapeDtypeStruct(jax.export.symbolic_shape("B, 128"), jnp.float32)
out_spec = jax.eval_shape(f, x_spec)
print(out_spec.shape)
```

The expected result would be `('B', 64)` as the shape, meaning an unknown B carried through to the output’s first dimension, and 64 as the second (assuming the layer’s weights are fixed shape). This pattern – one dimension named and others concrete – is fully supported. In fact, JAX’s shape polymorphism rules allow mixing symbolic and concrete parts of shapes. The documentation gives an example for a function with two arguments where only the first argument’s leading dimension is polymorphic: `polymorphic_shapes=["(b, _, _)", None]` means *treat the first arg’s shape as `(b, *, *)` (with `b` symbolic and the other dims filled from the actual arg), and do not introduce any symbolic dims for the second arg* ([jax/jax/experimental/jax2tf/README.md at main · jax-ml/jax · GitHub](https://github.com/google/jax/blob/main/jax/experimental/jax2tf/README.md#:~:text=%2A%20%60polymorphic_shapes%3D%5B,which%20must%20be)). By analogy, a single-argument spec `"(B, _)"` would mark just the first dimension as `B` and use the actual value of the second dimension (128 in our case) as fixed. In our code above we directly wrote `"B, 128"` which explicitly sets second dim to 128 – both approaches result in a shape spec where only `B` is the variable.

Under the hood, `jax.eval_shape` will return a `ShapeDtypeStruct` for the output. You can access `out_spec.shape` (as we did) to get the tuple `('B', 64)`. This tuple contains Python objects representing the dimension variables. If you print it, they often appear as strings or `DimExpr` expressions (the JAX printer shows `'B'` in quotes to indicate it's a named dimension, and something like `4*B` for expressions). You don’t usually manipulate these objects directly; they’re mainly for JAX’s internal use and for printing. But you **can** convert them to strings via `str(out_spec.shape)` if needed, which would yield a string like `"(B, 64)"`. In fact, JAX’s `jax2tf` utilities do exactly that to communicate shapes externally ([jax/jax/experimental/jax2tf/jax2tf.py at main · jax-ml/jax · GitHub](https://github.com/google/jax/blob/main/jax/experimental/jax2tf/jax2tf.py#:~:text=,str)).

## Real-World Usage and References  
The pattern of using `jax.eval_shape` with symbolic dimensions is actively used in JAX’s ecosystem for shape-polymorphic code: 

- **JAX2TF (TensorFlow conversion)** – The JAX team’s `jax2tf.convert` supports polymorphic shapes by internally using `jax.eval_shape`. They offer an API `jax2tf.eval_polymorphic_shape` that essentially wraps `jax.eval_shape` for symbolic shapes. In the JAX codebase, this is implemented by constructing symbolic input specs and then doing `res_poly_spec = jax.eval_shape(fun, *args_poly_specs)` ([jax/jax/experimental/jax2tf/jax2tf.py at main · jax-ml/jax · GitHub](https://github.com/google/jax/blob/main/jax/experimental/jax2tf/jax2tf.py#:~:text=args_specs%2C%20polymorphic_shapes)). The result `res_poly_spec` is a `ShapeDtypeStruct` (or PyTree of them) whose `.shape` may include symbols. For example, as shown earlier, given polymorphic shapes `"a, b"` and `"b, c"` for inputs, `jax.eval_shape` returns an output spec with shape `("a", "c")` ([jax/jax/experimental/jax2tf/jax2tf.py at main · jax-ml/jax · GitHub](https://github.com/google/jax/blob/main/jax/experimental/jax2tf/jax2tf.py#:~:text=,A%2C%20x)). This confirms that the method works and is used in a real project (the conversion tool). The second part of their result, `out_poly_shape`, is basically a tuple of the dimension variables `(a, c)` that can be fed into another call or used in error messages ([jax/jax/experimental/jax2tf/jax2tf.py at main · jax-ml/jax · GitHub](https://github.com/google/jax/blob/main/jax/experimental/jax2tf/jax2tf.py#:~:text=%28)). This design lets `jax2tf` export a TensorFlow `tf.Function` with undefined dimensions corresponding to JAX’s symbols.  

- **JAX Export** – JAX’s experimental export module (now `jax.export`) allows saving a compiled computation with shape polymorphism. It uses a similar strategy: you provide `jax.ShapeDtypeStruct` specs with `jax.export.symbolic_shape(...)` to indicate which dims are dynamic. The export process records the abstract avals (shapes with dimension variables) for inputs and outputs. The JAX docs show an example of exporting a function with symbolic dimensions: e.g., an input of shape `(a, b)` and output shape `(a, 2*b)` ([Shape polymorphism — JAX  documentation](https://docs.jax.dev/en/latest/export/shape_poly.html#:~:text=,b)) ([Shape polymorphism — JAX  documentation](https://docs.jax.dev/en/latest/export/shape_poly.html#:~:text=%28ShapedArray%28int32%5Ba%2Cb%5D%29%2C%29%20%3E%3E%3E%20exp.out_avals%20%28ShapedArray%28int32%5Ba%2C2)). After exporting, you can call the saved function with concrete values for `a` and `b` without retracing. This feature uses the same machinery – the shapes `a` and `b` are carried as symbols in the `ShapedArray` avals ([Shape polymorphism — JAX  documentation](https://docs.jax.dev/en/latest/export/shape_poly.html#:~:text=,b)). While this is ahead-of-time export rather than on-the-fly `eval_shape`, it underlines that shape inference with symbols is a first-class concept in JAX now. (Notably, older versions of JAX required a `PolyShape` helper class for this, but as of 0.4.x and above, using shape-spec strings like `"a, b"` is the preferred approach ([Change log — JAX  documentation](https://jax.readthedocs.io/en/latest/changelog.html?spm=a2c6h.13046898.publish-article.178.66da6ffajSshee#:~:text=,19284)).)

In summary, **to implement an `abstract_eval` for custom primitives using `jax.eval_shape`** in a library like jax2onnx, you can follow this recipe:
1. **Define a wrapper function** (or lambda) that calls your primitive with the necessary number and order of arguments. This function should be expressible in JAX – e.g., if your primitive isn’t natively known to JAX, you might have a placeholder or simplified computation for shape purposes.
2. **Prepare symbolic shape specs for inputs**. For each input array to the primitive, determine which dimensions should be dynamic. Use `jax.ShapeDtypeStruct(symbolic_shape("..."), dtype)` to make a spec. For example, if your primitive takes an input of shape `(B, 128)` (dynamic batch, fixed features), use `symbolic_shape("B, 128")`. If it has multiple inputs that share a dimension, use the same name in both specs (e.g. `"(B, 128)"` and `"(B, 64)"` for two inputs sharing batch size).
3. **Call** `jax.eval_shape(wrapper_fun, *input_specs)`. This will return the output shape spec(s). The `shape` attribute of the result will include any symbolic dimensions or expressions. For instance, if your primitive outputs something with the same batch `B`, you’ll see `'B'` in the output shape. If it reduces or expands dimensions in some formula, you’ll see the formula (e.g. `B*2` for doubling the length, etc.).
4. **Extract the shape information**. You can directly use the `ShapeDtypeStruct` (it’s likely what you need to feed into ONNX shape definitions). The `.shape` tuple can be converted to strings for logging or matched against expected patterns. Since JAX’s dimension variables are *opaque* (they’re not simple Python strings internally, even though they print as such), you might use `str(shape)` or the same helper JAX uses (as shown in `jax2tf`, they do `str(r.shape)` on each result ([jax/jax/experimental/jax2tf/jax2tf.py at main · jax-ml/jax · GitHub](https://github.com/google/jax/blob/main/jax/experimental/jax2tf/jax2tf.py#:~:text=,str))) to get a human-readable symbolic shape.

By leveraging JAX’s own abstract interpreter, you avoid re-implementing shape logic for each primitive – you effectively ask JAX, *“if these inputs have shapes (B, 128), etc., what shape would the output be?”* and JAX responds with a symbolic shape result. This approach has been **tested in official JAX code**. The JAX team’s conversion tools and exporter use `jax.eval_shape` under the hood for polymorphic shapes, confirming its reliability for this purpose ([jax/jax/experimental/jax2tf/jax2tf.py at main · jax-ml/jax · GitHub](https://github.com/google/jax/blob/main/jax/experimental/jax2tf/jax2tf.py#:~:text=args_specs%2C%20polymorphic_shapes)) ([jax/jax/experimental/jax2tf/jax2tf.py at main · jax-ml/jax · GitHub](https://github.com/google/jax/blob/main/jax/experimental/jax2tf/jax2tf.py#:~:text=,A%2C%20x)). 

Finally, remember that shape polymorphism is still an evolving feature. Ensure the `JAX_ENABLE_SHAPE_POLYMORPHISM` flag (if any is needed in 0.6.0) is set or that you’re using the API as documented for that version. Given the momentum in JAX development, by 0.6.0 the string-based polymorphic shapes are the standard (the older `PolyShape` objects are deprecated ([Change log — JAX  documentation](https://jax.readthedocs.io/en/latest/changelog.html?spm=a2c6h.13046898.publish-article.178.66da6ffajSshee#:~:text=,19284))). Using `jax.eval_shape` with `ShapeDtypeStruct` inputs as shown above is the recommended way to perform shape inference with dynamic dimensions in JAX 0.6.0. 

**Sources:**

- JAX shape polymorphism documentation and examples ([jax/jax/experimental/jax2tf/README.md at main · jax-ml/jax · GitHub](https://github.com/google/jax/blob/main/jax/experimental/jax2tf/README.md#:~:text=The%20,are%20assumed%20to%20range%20over)) ([jax/jax/experimental/jax2tf/README.md at main · jax-ml/jax · GitHub](https://github.com/google/jax/blob/main/jax/experimental/jax2tf/README.md#:~:text=%2A%20%60polymorphic_shapes%3D%5B,which%20must%20be))  
- JAX2TF usage of `jax.eval_shape` for polymorphic shapes (JAX GitHub) ([jax/jax/experimental/jax2tf/jax2tf.py at main · jax-ml/jax · GitHub](https://github.com/google/jax/blob/main/jax/experimental/jax2tf/jax2tf.py#:~:text=,A%2C%20x)) ([jax/jax/experimental/jax2tf/jax2tf.py at main · jax-ml/jax · GitHub](https://github.com/google/jax/blob/main/jax/experimental/jax2tf/jax2tf.py#:~:text=args_specs%2C%20polymorphic_shapes))  
- JAX export and shape inference with dimension variables (JAX docs) ([Shape polymorphism — JAX  documentation](https://docs.jax.dev/en/latest/export/shape_poly.html#:~:text=,b)) ([Shape polymorphism — JAX  documentation](https://docs.jax.dev/en/latest/export/shape_poly.html#:~:text=For%20example%2C%20in%20the%20following,as%20the%20new%20shape))