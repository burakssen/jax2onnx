# file: scripts/generate_readme.py

import os
import time
import logging
import subprocess
import json
import importlib.util
from typing import Any, Dict, List, Tuple

# Configure logging
logging.basicConfig(level=logging.INFO, format="%(message)s")

# Paths
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
PLUGIN_DIR = os.path.join(BASE_DIR, "../jax2onnx/plugins")
EXAMPLES_DIR = os.path.join(BASE_DIR, "../jax2onnx/examples")
TESTS_DIR = os.path.join(BASE_DIR, "../tests")
README_PATH = os.path.join(BASE_DIR, "../README.md")

# Markers for auto-generated sections in README.md
START_MARKER = "<!-- AUTOGENERATED TABLE START -->"
END_MARKER = "<!-- AUTOGENERATED TABLE END -->"
EXAMPLES_START_MARKER = "<!-- AUTOGENERATED EXAMPLES TABLE START -->"
EXAMPLES_END_MARKER = "<!-- AUTOGENERATED EXAMPLES TABLE END -->"

NETRON_BASE_URL = "https://netron.app/?url=https://enpasos.github.io/jax2onnx/onnx/"

# --- Helper Functions ---


def get_plugin_from_source(source: str) -> str:
    return source.split(".")[-1]


try:
    from tests.t_generator import load_metadata_from_dir
except ImportError:

    def load_metadata_from_dir(
        directory: str, exclude_files=None
    ) -> List[Dict[str, Any]]:
        exclude_files = exclude_files or ["__init__.py"]
        metadata_list = []
        for root, _, files in os.walk(directory):
            for file in files:
                if file.endswith(".py") and file not in exclude_files:
                    module_path = os.path.join(root, file)
                    module_name = module_path.replace(os.sep, ".").replace(".py", "")
                    spec = importlib.util.spec_from_file_location(
                        module_name, module_path
                    )
                    if spec and spec.loader:
                        module = importlib.util.module_from_spec(spec)
                        spec.loader.exec_module(module)
                        if hasattr(module, "get_metadata"):
                            md = module.get_metadata()
                            md = md if isinstance(md, list) else [md]
                            for entry in md:
                                # Handle both old and new formats
                                if "testcases" in entry:
                                    # New format - testcases is a list of dicts or a dict
                                    testcases = entry.get("testcases", [])
                                    if isinstance(testcases, list):
                                        for testcase in testcases:
                                            # If testcase is a string, convert to dict
                                            if isinstance(testcase, str):
                                                tc_data = {
                                                    "testcase": testcase,
                                                    "source": module_name,
                                                    "context": entry.get(
                                                        "context", "default"
                                                    ),
                                                    "component": entry.get(
                                                        "component", file[:-3]
                                                    ),
                                                }
                                                metadata_list.append(tc_data)
                                            else:
                                                # It's already a dict
                                                testcase["source"] = module_name
                                                testcase["context"] = entry.get(
                                                    "context", "default"
                                                )
                                                testcase["component"] = entry.get(
                                                    "component", file[:-3]
                                                )
                                                metadata_list.append(testcase)
                                    elif isinstance(testcases, dict):
                                        # Handle testcases as dict (key: testcase name, value: status)
                                        for tc_name, status in testcases.items():
                                            tc_data = {
                                                "testcase": tc_name,
                                                "status": status,
                                                "source": module_name,
                                                "context": entry.get(
                                                    "context", "default"
                                                ),
                                                "component": entry.get(
                                                    "component", file[:-3]
                                                ),
                                            }
                                            metadata_list.append(tc_data)
                                else:
                                    # Assume entry itself is a testcase entry (old format)
                                    entry["source"] = module_name
                                    if "context" not in entry:
                                        entry["context"] = "default"
                                    if "component" not in entry:
                                        entry["component"] = file[:-3]
                                    metadata_list.append(entry)
        return metadata_list


# --- Running Tests ---


def run_pytest() -> Dict:
    """Runs pytest and captures pass/fail results using JSON output."""
    logging.info("🛠 Running full tests...")
    report_dir = os.path.join(BASE_DIR, "output")
    os.makedirs(report_dir, exist_ok=True)
    report_path = os.path.join(report_dir, "pytest_report.json")

    # subprocess.run(
    #     ["pytest", "--json-report", f"--json-report-file={report_path}"],
    #     capture_output=True,
    #     text=True,
    #     check=True,
    # )

    test_results = {}
    if os.path.exists(report_path):
        with open(report_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        for test in data.get("tests", []):
            partA, partB, partC = test["nodeid"].split("::")
            partAs = partA.split("/")
            testcase_name = (
                partC.replace("test_", "") if partC.startswith("test_") else partC
            )
            situation = partAs[1]  # expecting "examples" or "primitives"
            context = partAs[-1]

            context = (
                context.replace("test_", "") if context.startswith("test_") else context
            )
            context = context.replace(".py", "") if context.endswith(".py") else context
            context = situation + "." + context
            plugin = partB.replace("Test_", "") if partB.startswith("Test_") else partB

            status = "✅" if test["outcome"] == "passed" else "❌"
            key = (context, plugin, testcase_name)
            test_results[key] = status

    logging.info(f"✅ Tests completed. {len(test_results)} results captured.")

    return test_results


# --- Metadata Extraction and Aggregation ---


def extract_metadata(base_path: str, source_type: str) -> List[Dict[str, Any]]:
    logging.info(f"📡 Extracting metadata from {source_type.lower()}s...")
    if source_type.lower() == "plugins":
        exclude = [
            "__init__.py",
            "plugin_interface.py",
            "plugin_registry.py",
            "plugin_registry_static.py",
        ]
    else:
        exclude = ["__init__.py"]
    metadata_list = load_metadata_from_dir(base_path, exclude)

    # Convert metadata entries to a uniform format
    for entry in metadata_list:
        # Make sure all entries have a testcase field
        if "testcase" not in entry and "testcases" not in entry:
            # If neither exists, create an empty testcases dict
            entry["testcases"] = {}
        elif "testcase" in entry and "testcases" not in entry:
            # If only testcase exists, create a testcases entry from it
            entry["testcases"] = {entry["testcase"]: "➖"}
        elif "testcases" in entry:
            # If testcases exists but is a list, convert to dict mapping
            if isinstance(entry["testcases"], list):
                if all(isinstance(tc, str) for tc in entry["testcases"]):
                    # List of strings
                    entry["testcases"] = {tc: "➖" for tc in entry["testcases"]}
                else:
                    # List of dicts, extract testcase names
                    entry["testcases"] = {
                        tc.get("testcase", ""): tc.get("status", "➖")
                        for tc in entry["testcases"]
                        if isinstance(tc, dict)
                    }

    logging.info(f"✅ {len(metadata_list)} {source_type.lower()} components found.")
    return metadata_list


def aggregate_metadata(
    entries: List[Dict[str, Any]],
) -> Dict[Tuple[str, str], Dict[str, Any]]:
    """
    Group individual test case metadata entries by (context, component)
    and aggregate test case statuses.
    """
    grouped = {}
    for entry in entries:
        context = entry.get("context", "default")
        component = entry.get("component", "Unknown")
        key = (context, component)
        if key not in grouped:
            grouped[key] = {
                "component": entry.get("component", entry.get("component", "Unknown")),
                "source": entry.get("source", "#"),
                "jax_doc": entry.get("jax_doc", "#"),
                "onnx": set(),
                "since": entry.get("since", ""),
                "description": entry.get("description", ""),
                "children": entry.get("children", []),
                "testcases": {},
            }

        # For plugins, accumulate ONNX operator links if available.
        for op in entry.get("onnx", []):
            if isinstance(op, dict):
                grouped[key]["onnx"].add(
                    f"[{op.get('component', '')}]({op.get('doc', '#')})"
                )
            elif isinstance(op, str):
                grouped[key]["onnx"].add(f"[{op}](#)")

        # Record test case info - handle both individual testcase and testcases dict
        if "testcase" in entry:
            tc_name = entry.get("testcase", "")
            if tc_name:
                grouped[key]["testcases"][tc_name] = entry.get("status", "➖")

        # Also consider testcases dict if present
        if "testcases" in entry and isinstance(entry["testcases"], dict):
            for tc_name, status in entry["testcases"].items():
                if tc_name:  # Skip empty testcase names
                    grouped[key]["testcases"][tc_name] = status

    return grouped


def merge_test_results(
    grouped: Dict[Tuple[str, str], Dict[str, Any]], test_results: Dict
) -> Dict[Tuple[str, str], Dict[str, Any]]:
    """
    Update the grouped metadata with test result statuses.
    Test result keys are tuples: (context, plugin, testcase).
    For plugins, we consider the plugin name as the short form of the jax component.
    """
    for (context, component), data in grouped.items():
        # Use plugin from jax_component (or component) to lookup test result.
        plugin = get_plugin_from_source(data.get("component", component))

        # make a copy of data["testcases"] to avoid changing the original dict while iterating
        copy = data["testcases"].copy()
        for tc_ in copy:
            candidates = []
            if (context, plugin, tc_ + "_dynamic") in test_results:
                candidates.append(tc_ + "_dynamic")
                candidates.append(tc_ + "_concrete")
                # remove the original testcase from the dict
                del data["testcases"][tc_]
            else:
                candidates.append(tc_)
            for tc in candidates:
                if tc_ == tc or (context, plugin, tc) in test_results:
                    status = test_results.get((context, plugin, tc), "➖")
                    url = f"{NETRON_BASE_URL}{context.replace('.', '/')}/{tc}.onnx"
                    data["testcases"][tc] = f"[`{tc}`]({url}) {status}"
    return grouped


# --- README Update ---


def update_readme(
    metadata_plugins: List[Dict[str, Any]],
    metadata_examples: List[Dict[str, Any]],
    test_results: Dict,
):
    logging.info("📄 Updating README...")
    # Aggregate individual testcases by component.
    plugins_grouped = aggregate_metadata(metadata_plugins)
    examples_grouped = aggregate_metadata(metadata_examples)

    # Merge test results into the aggregated groups.
    plugins_grouped = merge_test_results(plugins_grouped, test_results)
    examples_grouped = merge_test_results(examples_grouped, test_results)

    # Build table rows for plugins.
    plugin_rows = []
    for (context, component), data in sorted(plugins_grouped.items()):

        comp_name = data["component"]
        # Prepend context to the component name if it's not default
        if context != "default":
            comp_name = f"{context}.{comp_name}"
        # Remove "plugin." prefix from the component name
        comp_name = comp_name.removeprefix("plugins.")

        jax_comp = f"[{comp_name}]({data['jax_doc']})"
        onnx_components = "<br>".join(sorted(data["onnx"])) if data["onnx"] else "➖"
        testcases_str = (
            "<br>".join(sorted(data["testcases"].values()))
            if data["testcases"]
            else "➖"
        )
        since = data["since"]
        row = f"| {jax_comp} | {onnx_components} | {testcases_str} | {since} |"
        plugin_rows.append(row)

    # Build table rows for examples.
    example_rows = []
    for (context, component), data in sorted(examples_grouped.items()):
        # For examples we might have additional fields such as description or children.
        description = data.get("description", "")
        children = data.get("children", [])
        children_str = "<br>".join(children) if children else "➖"
        testcases_str = (
            "<br>".join(sorted(data["testcases"].values()))
            if data["testcases"]
            else "➖"
        )
        since = data["since"]
        row = f"| {component} | {description} | {children_str} | {testcases_str} | {since} |"
        example_rows.append(row)

    table_header_plugins = (
        "| JAX Component | ONNX Components | Testcases | Since |\n"
        "|:-------------|:---------------|:---------|:------|"
    )
    table_header_examples = (
        "| Component | Description | Children | Testcases | Since |\n"
        "|:----------|:------------|:---------|:---------|:------|"
    )

    table_plugins = "\n".join(plugin_rows)
    table_examples = "\n".join(example_rows)

    with open(README_PATH, "r", encoding="utf-8") as f:
        readme_content = f.read()

    # Replace plugins table.
    start_idx = readme_content.find(START_MARKER)
    end_idx = readme_content.find(END_MARKER)
    if start_idx == -1 or end_idx == -1:
        raise ValueError("Plugin markers not found in README.md")
    new_plugins_section = (
        f"{START_MARKER}\n\n{table_header_plugins}\n{table_plugins}\n\n{END_MARKER}"
    )
    readme_content = (
        readme_content[:start_idx]
        + new_plugins_section
        + readme_content[end_idx + len(END_MARKER) :]
    )

    # Replace examples table.
    start_idx = readme_content.find(EXAMPLES_START_MARKER)
    end_idx = readme_content.find(EXAMPLES_END_MARKER)
    if start_idx == -1 or end_idx == -1:
        raise ValueError("Examples markers not found in README.md")
    new_examples_section = f"{EXAMPLES_START_MARKER}\n\n{table_header_examples}\n{table_examples}\n\n{EXAMPLES_END_MARKER}"
    readme_content = (
        readme_content[:start_idx]
        + new_examples_section
        + readme_content[end_idx + len(EXAMPLES_END_MARKER) :]
    )

    with open(README_PATH, "w", encoding="utf-8") as f:
        f.write(readme_content)

    logging.info("✅ README.md updated successfully!")


# --- Main Execution ---

if __name__ == "__main__":
    start_time = time.time()
    test_results = run_pytest()
    metadata_plugins = extract_metadata(PLUGIN_DIR, "plugins")
    metadata_examples = extract_metadata(EXAMPLES_DIR, "examples")

    # remove test_results, metadata_plugins, metadata_examples not including testcase with "linear_general"
    # test = "autoencoder"
    # test_results = {k: v for k, v in test_results.items() if test in k}
    # metadata_plugins = [entry for entry in metadata_plugins if "testcase" in entry and test in entry["testcase"].lower()]
    # metadata_examples = [entry for entry in metadata_examples if "testcase" in entry and test in entry["testcase"].lower()]

    update_readme(metadata_plugins, metadata_examples, test_results)
    logging.info(f"⏳ Total execution time: {time.time() - start_time:.2f}s")
